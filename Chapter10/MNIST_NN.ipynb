{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant libraries\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot\n",
    "%matplotlib inline\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to convert data into csv file\n",
    "\n",
    "def convert(imgs, labels, outfile, n):\n",
    "\n",
    "    imgf = open(imgs, \"rb\")\n",
    "    labelf = open(labels, \"rb\")\n",
    "    csvf = open(outfile, \"w\")\n",
    "\n",
    "    imgf.read(16)\n",
    "    labelf.read(8)\n",
    "    images = []\n",
    "\n",
    "    for i in range(n):\n",
    "        image = [ord(labelf.read(1))]\n",
    "        for j in range(28*28):\n",
    "            image.append(ord(imgf.read(1)))\n",
    "        images.append(image)\n",
    "\n",
    "    for image in images:\n",
    "        csvf.write(\",\".join(str(pix) for pix in image)+\"\\n\")\n",
    "        \n",
    "    imgf.close()\n",
    "    labelf.close()\n",
    "    csvf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in training and testing data\n",
    "\n",
    "mnist_train_x = \"/Users/kavittolia/code/islp/Chapter10/mnist/train-images.idx3-ubyte\"\n",
    "mnist_train_y = \"/Users/kavittolia/code/islp/Chapter10/mnist/train-labels.idx1-ubyte\"\n",
    "mnist_test_x = \"/Users/kavittolia/code/islp/Chapter10/mnist/t10k-images.idx3-ubyte\"\n",
    "mnist_test_y = \"/Users/kavittolia/code/islp/Chapter10/mnist/t10k-labels.idx1-ubyte\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data into csv files\n",
    "\n",
    "convert(mnist_train_x, mnist_train_y, \"/Users/kavittolia/code/islp/Chapter10/mnist/train.csv\", 60000)\n",
    "convert(mnist_test_x, mnist_test_y, \"/Users/kavittolia/code/islp/Chapter10/mnist/test.csv\", 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the training data is accurate\n",
    "\n",
    "train_file = open(\"/Users/kavittolia/code/islp/Chapter10/mnist/train.csv\", \"r\")\n",
    "train_list = train_file.readlines()\n",
    "train_file.close()\n",
    "print(len(train_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The output gives you the digit and then the pixel scores\n",
    "\n",
    "train_list[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the digit image is as expected\n",
    "\n",
    "values = train_list[10].split(\",\")\n",
    "image_array = np.asfarray(values[1:]).reshape(28,28)\n",
    "matplotlib.pyplot.style.use('dark_background')\n",
    "matplotlib.pyplot.imshow(image_array, cmap=\"Greys_r\", interpolation=\"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the test data is accurate\n",
    "\n",
    "test_file = open(\"/Users/kavittolia/code/islp/Chapter10/mnist/test.csv\", \"r\")\n",
    "test_list = test_file.readlines()\n",
    "test_file.close()\n",
    "print(len(test_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the neural network, we need 784 inputs and two hidden layers\n",
    "# Hidden layer 1 will have 128 nodes\n",
    "# Hidden layer 2 will have 64 nodes\n",
    "\n",
    "class DNN:\n",
    "\n",
    "    def __init__(self, sizes, epochs, lr):\n",
    "        self.sizes = sizes\n",
    "        self.epochs = epochs\n",
    "        self.learning_rate = lr\n",
    "        input_layer = sizes[0]\n",
    "        hidden_1 = sizes[1]\n",
    "        hidden_2 = sizes[2]\n",
    "        output_layer = sizes[3]\n",
    "        self.params = {\n",
    "            'W1': np.random.randn(hidden_1, input_layer) * np.sqrt(1./hidden_1),       # 128 x 784\n",
    "            'W2': np.random.randn(hidden_2, hidden_1) * np.sqrt(1./hidden_2),          # 64 x 128\n",
    "            'W3': np.random.randn(output_layer, hidden_2) * np.sqrt(1./output_layer)   # 10 x 64\n",
    "        }\n",
    "\n",
    "    def activation_function(self, x, func_type, derivative=False):\n",
    "        if derivative:\n",
    "            if func_type == 'sigmoid':\n",
    "                return (np.exp(-x)) / ((np.exp(-x) + 1) ** 2)\n",
    "            elif func_type == 'tanh':\n",
    "                return 1 - (((np.exp(x) - np.exp(-x)) ** 2) / ((np.exp(x) + np.exp(-x)) ** 2))\n",
    "            elif func_type == 'softmax':\n",
    "                exps = np.exp(x-x.max())\n",
    "                return exps / np.sum(exps, axis=0) * (1 - exps / np.sum(exps, axis=0))\n",
    "            elif func_type == 'relu':\n",
    "                return (x > 0) * 1\n",
    "            else:\n",
    "                print('Unrecognised activation function!')\n",
    "        else:\n",
    "            if func_type == 'sigmoid':\n",
    "                return 1 / (1 + np.exp(-x))\n",
    "            elif func_type == 'tanh':\n",
    "                return (np.exp(x) - np.exp(-x)) / (np.exp(x) + np.exp(-x))\n",
    "            elif func_type == 'softmax':\n",
    "                exps = np.exp(x-x.max())\n",
    "                return exps / np.sum(exps, axis=0)\n",
    "            elif func_type == 'relu':\n",
    "                return np.maximum(0.0, x)\n",
    "            else:\n",
    "                print('Unrecognised activation function!')            \n",
    "\n",
    "    def forward_pass(self, x_train, func_type):\n",
    "        params = self.params\n",
    "        params['A0'] = x_train                              # 784 x 1\n",
    "        # input_layer to hidden_1\n",
    "        params['Z1'] = np.dot(params['W1'], params['A0'])   # 128 x 1\n",
    "        params['A1'] = self.activation_function(params['Z1'], func_type)\n",
    "        # hidden_1 to hidden_2\n",
    "        params['Z2'] = np.dot(params['W2'], params['A1'])   # 64 x 1\n",
    "        params['A2'] = self.activation_function(params['Z2'], func_type)\n",
    "        # hidden_2 to output_layer\n",
    "        params['Z3'] = np.dot(params['W3'], params['A2'])   # 10 x 1\n",
    "        params['A3'] = self.activation_function(params['Z3'], 'softmax')\n",
    "        return params['Z3']\n",
    "\n",
    "    def backward_pass(self, y_train, output, func_type):\n",
    "        params = self.params\n",
    "        change_w = {}\n",
    "        # calculate W3 update\n",
    "        error = 2 * (output - y_train) / output.shape[0] * self.activation_function(params['Z3'], 'softmax', derivative=True)\n",
    "        change_w['W3'] = np.outer(error, params['A2'])\n",
    "        # calculate W2 update\n",
    "        error = np.dot(params['W3'].T, error) * self.activation_function(params['Z2'], func_type, derivative=True)\n",
    "        change_w['W2'] = np.outer(error, params['A1'])\n",
    "        # calculate W1 update\n",
    "        error = np.dot(params['W2'].T, error) * self.activation_function(params['Z1'], func_type, derivative=True)\n",
    "        change_w['W1'] = np.outer(error, params['A0'])\n",
    "        return change_w\n",
    "\n",
    "    def update_weights(self, change_w):\n",
    "        for param_name, gradient in change_w.items():\n",
    "            self.params[param_name] -= self.learning_rate * gradient      # W_t+1 = W_t - lr * Delta_W_t           \n",
    "\n",
    "    def compute_accuracy(self, test_data, func_type):\n",
    "        predictions = []\n",
    "        for x in test_data:\n",
    "            values = x.split(\",\")\n",
    "            inputs = (np.asfarray(values[1:]) / 255.0 * 0.99) + 0.01\n",
    "            targets = np.zeros(10) + 0.01\n",
    "            targets[int(values[0])] = 0.99\n",
    "            output = self.forward_pass(inputs, func_type)\n",
    "            pred = np.argmax(output)\n",
    "            predictions.append(pred==np.argmax(targets))\n",
    "        return np.mean(predictions)\n",
    "    \n",
    "    def predict_image(self, test_image, func_type):\n",
    "        values = test_image.split(\",\")\n",
    "        inputs = (np.asfarray(values[1:]) / 255.0 * 0.99) + 0.01\n",
    "        output = self.forward_pass(inputs, func_type)\n",
    "        return np.argmax(output)\n",
    "\n",
    "    def train(self, train_list, test_list, func_type):\n",
    "        output_data = []\n",
    "        for i in range(self.epochs):\n",
    "            start_time = time.time()\n",
    "            for x in train_list:\n",
    "                values = x.split(\",\")\n",
    "                inputs = (np.asfarray(values[1:]) / 255.0 * 0.99) + 0.01\n",
    "                targets = np.zeros(10) + 0.01\n",
    "                targets[int(values[0])] = 0.99\n",
    "                output = self.forward_pass(inputs, func_type)\n",
    "                change_w = self.backward_pass(targets, output, func_type)\n",
    "                self.update_weights(change_w)\n",
    "            accuracy = self.compute_accuracy(test_list, func_type)\n",
    "            print('Epoch: {0}, Time Spent: {1:.02f}s, Accuracy: {2:.2f}%, Learning Rate: {3}, Activation Function: {4}'.format(i + 1, time.time() - start_time, accuracy * 100, self.learning_rate, func_type))\n",
    "            output_data.append([i + 1, time.time() - start_time, accuracy * 100, self.learning_rate, func_type])\n",
    "        return output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn = DNN(sizes=[784, 128, 64, 10], epochs=10, lr=1)\n",
    "output_data = dnn.train(train_list, test_list, 'tanh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test random image\n",
    "idx = 10\n",
    "values = test_list[idx].split(\",\")\n",
    "image_array = np.asfarray(values[1:]).reshape(28,28)\n",
    "matplotlib.pyplot.style.use('dark_background')\n",
    "matplotlib.pyplot.imshow(image_array, cmap=\"Greys_r\", interpolation=\"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn.predict_image(test_list[idx], 'tanh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create gibberish digit\n",
    "rubbish_vector = np.random.randint(0, 256, (785))\n",
    "rubbish_matrix = rubbish_vector[1:].reshape(28,28)\n",
    "matplotlib.pyplot.style.use('dark_background')\n",
    "matplotlib.pyplot.imshow(rubbish_matrix, cmap=\"Greys_r\", interpolation=\"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rubbish_str = ','.join(map(str, rubbish_vector)) \n",
    "dnn.predict_image(rubbish_str, 'tanh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Researching how learning rates and activation functions co-behave\n",
    "\n",
    "lr_list = [1, 0.1, 0.01, 0.001]\n",
    "act_func_list = ['sigmoid', 'tanh', 'relu']\n",
    "\n",
    "dnn_list = []\n",
    "output_all = []\n",
    "\n",
    "for lr_iter in lr_list:\n",
    "    dnn = DNN(sizes=[784, 128, 64, 10], epochs=10, lr=lr_iter)\n",
    "    for act_func in act_func_list:\n",
    "        output_all.append(dnn.train(train_list, test_list, act_func))\n",
    "        dnn_list.append(dnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(np.concatenate(output_all))\n",
    "df.to_csv(\"output_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"output_data.csv\", index_col=0).rename(columns={\"0\": \"epoch\", \"1\": \"time\", \"2\": \"accuracy\", \"3\": \"learning_rate\", \"4\": \"activation\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "px.line(\n",
    "    df,\n",
    "    x=\"epoch\",\n",
    "    y=\"accuracy\",\n",
    "    color=\"activation\",\n",
    "    facet_col=\"learning_rate\",\n",
    "    facet_col_wrap=2,\n",
    "    height=600,\n",
    "    log_y=True,\n",
    ").update_yaxes(matches=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "islp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
